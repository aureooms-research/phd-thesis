\section{Algorithms}%
\label{sec:models-of-computation:algorithms}

We study two classes of algorithms: uniform and nonuniform.

\emph{Uniform} algorithms are considered practical. They can be implemented on
a real computer because they take care of data management issues in an
automated way.

\emph{Nonuniform} algorithms ignore the data management aspect of practical
computation. They do not give details on how to structure the intermediate
results of their computation. Those results are assumed to be instantly
accessible without any organization. Since we consider problem instances of
arbitrarily large size, this is not possible in practice:
processor units can only hold a fixed amount of data at any given time. The
data has to be stored somewhere in some structured way.

The naming uniform simply means that the algorithm (its description) is the
same for all input sizes. This is what is generally expected from algorithm
design: to output a finite size description of an automated problem solving
method that works for any instance size.
%
Nonuniform algorithms on the other hand are allowed to have distinct
descriptions for each input size. Each nonuniform algorithm can be seen as an
infinite sequence of uniform algorithms \(A = A_1, A_2, \ldots\), each \(A_n\)
hardcoding the data management part in its description. This description
therefore is allowed to grow with \(n\).
Designing a nonuniform algorithm \(A\) amounts to describing a method
that given \(n\) outputs \(A_n\).

In this thesis, we study uniform
\emph{random access machine} (RAM) models,
the real-RAM and the word-RAM models,
%
and nonuniform decision tree models,
the algebraic computation tree,
algebraic decision tree,
and linear decision tree models.
%
Those are described in the following paragraphs.

\subsection{Random Access Machines}%
\label{sec:models-of-computation:algorithms:ram}

The real-RAM and word-RAM models have the RAM in common. They both assume a
memory storing numbers whose access cost is constant and a constant number of
standard operations on the numbers they manipulate.

Defined in 1978 by Shamos in his PhD thesis~\cite[Section~2.3]{Sha78},
the real-RAM model is a classic of Computational Geometry. The input is assumed
to consist of \(n\) real numbers and those numbers can be manipulated
exactly at constant cost using arithmetic and comparison operators.
This makes sense from the geometer's point of view since geometric data is
best abstracted as real numbers.
For data management purposes, the model also allows to manipulate \(\log
n\)-bits integers with arithmetic, comparison, and bitwise operators but does
not allow the conversion from a real number to an integer.

Defined in 1990 by Fredman and Willard~\cite{FW90},
the word-RAM model models computers as we know them more closely. It considers
an input consisting of \(n\) \(w\)-bits integers called words and allows a
constant number of standard unary or binary operators to be executed in
constant time.
%
Because of practical considerations,
those words can be assumed to have bitsize \(w \geq \log n\) (also called the
transdichotomous model).

\subsection{Computation and Decision Trees}%
\label{sec:models-of-computation:algorithms:trees}

A decision tree is a constant-degree rooted tree whose internal nodes encode
binary queries to an omniscient oracle and whose leaves encode the result of the
computation. The complexity of the tree is defined to be the length of
its longest root to leaf path called the \emph{depth} of the tree.

A decision tree cannot inspect the input directly.
To make progress, it inquires about the input through ``yes/no'' questions
asked to the oracle. The oracle answers those questions by ``yes'' or ``no''
honestly and accurately.

An identification problem consists in, given an input of size \(n\),
distinguishing among \(f(n)\) input classes, that is, to put the instance in
the right box. A decision problem is an identification where \(f(n) = 2\).

Of course, for every identification problem with \(f(n)\) input classes,
there is a decision tree that solves the problem by asking
\(O(\log f(n))\) ``yes/no'' questions of the form:
``Is the input in the following range of input classes?''
%
This is best possible: every query carries at most one additional bit of
information, and there are at least \(\lceil \log f(n) \rceil\) bits necessary
to label each input class. This lower bound is called the Information Theoretic
Lower Bound, or ITLB, and holds for any decision tree model.

The queries the above decision tree makes are too powerful to make the study of
this kind of model interesting in general.
%
Moreover, practically, those queries have no structure a priori and it is not at
all obvious how they can be encoded.
%
For a decision tree model to make sense, we have to restrict the kind of
queries that can be made.

\subsubsection{Linear Decision Trees}

A first natural way to restrict the complexity of the queries of our decision
tree model is to only allow linear queries on the input
(see for instance~\cite[Section~1]{Dob76},
\cite[Section~2]{DL78}, and~\cite[Section~4]{DL79}).
This will be sufficient to solve problems such as Sorting, Element Uniqueness,
3SUM, \(k\)-SUM, and subset-sum.

In the \emph{\(s\)-linear decision tree model}, queries consists
in testing the sign of a linear function on at most \(s\) numbers \(q_{i_1},\ldots,q_{i_s}\) of the
input \(q_1,\ldots,q_n\). Such a query is called a \(s\)-linear query and
can be written as
%
\begin{displaymath}
	\alpha_1 q_{i_1} + \cdots + \alpha_s q_{i_s} \ask{\leq} \alpha_0
\end{displaymath}
%
Each question is defined to cost a single unit. All other operations can be
carried out for free but may not examine the input vector $q$. We refer to
$n$-linear decision trees simply as linear decision trees.

Note that this model generalizes the Comparison Tree Model commonly used for
Sorting and Element Uniqueness, where queries have the form \(q_i \ask{\leq}
q_j\).

\subsubsection{Algebraic Decision Trees}
The linear decision tree model is not powerful enough for more complicated
problems. General Position Testing for instance involves discovering the sign
of quadratic polynomials of the input, which is impossible in general with
linear queries only.

The (bounded-degree) \emph{algebraic decision tree (ADT)}~\cite{R72,Y81,SY82}
is an algebraic generalization of linear decision trees.
An algebraic decision tree performs constant-cost branching operations that
amount to testing the sign of
a constant-degree polynomial of the input numbers.

In this model, for an input \(q_1,\ldots,q_n\), a query can be written as
\begin{displaymath}
	p(q_1, \ldots, q_n) \ask{\le} 0,
\end{displaymath}
where \(p \in \mathbb{R}[x_1,\ldots, x_n]\) is a polynomial of constant
degree. Again, operations not involving the input are free.

\subsubsection{Algebraic Computation Trees}
Computation trees differ from decision trees in that instead of exclusively
asking
``yes/no'' questions, they perform arithmetic operations on variables whose
results can be remembered and reused as operands, but only inspected using
comparison queries.
In the case of \emph{algebraic computation trees}~\cite{Be83},
this allows, for instance, to make decisions based on
arbitrary polynomial expressions of the input with a sane way of counting the
complexity of constructing such an expression. This would not be allowed in
the algebraic decision tree model.

The internal nodes of an algebraic computation tree are labeled with
arithmetic (\(r \gets o_1 \op o_2, \op \in \{\,+,-,\times,\div\,\}\)) and
branching (\(z : 0\)) operations. Any internal node labeled \(r \gets o_1 \op
o_2\) has outdegree one and is
such that either \(o_k = q_i\) for some \(i\) or there exists an ancestor \(o_k
\gets x \op y\) of this node, and any internal node labeled \(z : 0\) has
outdegree three and is such that either \(z = q_i\) for some \(i\) or there
exists an ancestor \(z \gets x \op y\) of this node.
Similarly to the previously described decision tree models, leafs of the tree
correspond to input classes.

Using this model can be interpreted as only counting the operations that
involve the input, that is, members of the input or results of previous
operations involving the input. All other arithmetic operations are for free.

