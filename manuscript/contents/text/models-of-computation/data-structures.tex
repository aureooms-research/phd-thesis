\section{Data Structures}%
\label{sec:models-of-computation:data-structures}

Data Structures are ubiquitous in algorithmics. Given some data, we want to
store it in computer memory in a way that 1) allows us to efficiently access
the information we want to extract from this data and 2) does not require too
much storage space. The term \emph{structure} is by opposition to a randomly
ordered stream of data.

Usually, a third important feature of those structures is that they can be also
updated efficiently if the underlying data changes. We do not study or use that
aspect in this thesis, instead we only require that those data structures can
be constructed from scratch in an efficient way. Data
structures allowing efficient updates are usually named \emph{dynamic}
while the ones we study are \emph{static} data structures.

Those intuitive concepts are summarized as follows:

\paragraph{Preprocessing Time} Given some data, the time it takes to construct
the corresponding data structure in the given computation model.

\paragraph{Space} The amount of space the data structure consumes in the given
computation model. Can be expressed in bits, words, memory cells, \dots

\paragraph{Query Time} Given a data structure, the time consumed by a
single query in the given computation model.
\\

In \S\ref{sec:models-of-computation:data-structures:encodings} we give a precise
definition of a particular type of data structure we study: encodings.
In \S\ref{sec:models-of-computation:data-structures:trees} we explicit a
connection between those encodings and nonuniform models of computation.

\subsection{Encodings}%
\label{sec:models-of-computation:data-structures:encodings}

A data structure is called \emph{succinct} if its space usage is close to the ITLB.
%
This concept was first introduced by Jacobson in his PhD thesis~\cite{Ja88}.
%
Since then, it has been extensively studied.
%
Raman et al. studied the dynamic implementation of such data
structures and gave the first rank-select succinct
data structures~\cite{RRS01,RRS07}.
%
%P{\u a}tra{\cb s}cu studied the succinct encoding of arrays of
%trits~\cite{Pa08}.
%
Those data structures are even efficient in practice as show by Vigna with
their implementations~\cite{Vi08}.

In this thesis, we also try to get good bounds on the space used by the data
structures we design. However, in most cases we are still very far from the
ITLB. We make all our data structure design problems fit in a single framework
dubbed \emph{instance encoding} so that their space and query time
requirements can be easily compared.

\todo{Include preprocessing in the definition?}

\input{text/definition/encoding}

In Papers~\ref{paper:order-type-encoding}~and~\ref{paper:3sum-encoding} we
design such encodings for order types of point configurations and 3SUM types of
lists of numbers. In the case of abstract order type we manage to
obtain a \emph{compact} data structure, that is, a \(O(\text{ITLB})\)-bits encoding
that allows efficient queries.

\subsection{Connection to Nonuniform Algorithms}%
\label{sec:models-of-computation:data-structures:trees}

% TODO Give example with k-SUM, CIO, ES and KLM.
% TODO Those yield succinct encoding from which the signs can be recovered.

%This is not necessarily true with algebraic decision trees because the answer
%set is not necessarily connected. With linear decision trees it is because the
%answer set is convex, and thus connected.

Given a realizable order type, instead of encoding the answers to all possible
of its order type queries, consider the problem of deciding whether one of
those queries answers \(0\).
This problem is the general position testing problem (GPT) and corresponds to
deciding whether an input set of points in the plane contains a collinear
triple.

It is an open question whether solving this problem can be done in subquadratic
time. In particular, no subquadratic constant-degree algebraic decision tree is
known for that problem.

A constant-degree algebraic decision tree is a rooted tree whose internal nodes are
labeled with inequalities of the form \(f(\text{input}) \leq 0\), where
\(f\) is a constant-degree polynomial,
and whose leaves are labeled with \emph{yes} or \emph{no}.

Observe the following: Assume we are given an instance of some real-input
decision problem. Given a (computable???) decision tree of depth \(D\) for this problem for which
each input query and answer can be encoded using at most \(Q\) bits, we can
encode the instance using at most \(DQ\) bits by encoding the path traversed when
executing the decision tree on this instance. The general position testing
problem (GPT) asks if an input set of \(n\) points in the plane contains a
collinear triple. It is an example of a real-input decision problem for which
no subquadratic real-RAM algorithm is known even though the best known lower
bound is \(\Omega(n \log n)\). Since shallow decision trees yield short encodings,
we see the design of a subquadratic encoding for realizable order types as a
stepping stone towards nonuniform and uniform subquadratic algorithms for
GPT\@.

Unfortunately, even though our encodings achieve subquadratic space for
realizable order types, they cannot be used to test for isomorphism in
subquadratic time. This is partly because the preprocessing time to construct
the encoding is already quadratic.
%
However, observe that the preprocessing time we achieve in this contribution
matches the best known upper bound for GPT in the algebraic decision tree
model:
\begin{theorem}
  If there is an encoding with construction cost \(C(N)\) for
  realizable order types in the algebraic decision tree model, then
  there is a nonuniform algorithm for general position testing that runs
  in time \(C(N)\) in the algebraic decision tree model.
\end{theorem}
%
\begin{proof}
  Construct the encoding. Then at zero cost in the nonuniform
  model, run all \(O(n^3)\) queries on the encoding.
\end{proof}
%
Goodman and Pollack saw GPT as a multidimensional generalization of
sorting~\cite{GP83}.
%
We again stress the need for a better understanding of this fundamental
problem.
