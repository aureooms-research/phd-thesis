\section{\(k\)-SUM}

\todo{Give at least one paragraph per citation on \(k\)-SUM.}

The \(k\)-SUM problem is a straightforward generalization of the 3SUM problem:
given a list of \(n\) real numbers, decide whether \(k\) of them sum to zero.

\input{text/definition/ksum}

We consider the \(k\)-SUM problem for \(k=O(1)\).
For fixed \(k\), the \(k\)-SUM problem can be solved in polynomial time
\(O(n^k)\) by testing all possible candidate solutions.
The interesting question is whether it is possible to improve on
this brute-force solution.

The \(k\)-SUM problem is a fixed-parameter version of the subset-sum problem, a
standard \textit{NP}-complete problem. The \(k\)-SUM problem, and in particular
the special case of 3SUM, has proved to be a cornerstone of the fine-grained
complexity program aiming at the construction of a complexity theory for
problems in $P$. In particular, there are deep connections between the
complexity of \(k\)-SUM, the Strong Exponential Time
Hypothesis~\cite{PW10,CGIMPS15}, and the complexity of many other major
problems in
\(\textsc{P}\)~\cite{GO95,BH99,MO01,P10,ACLL14,AVW14,GP18,KPP14,ALW14,AWY15,CL15}.
It has been known for long that \(k\)-SUM is $\textsc{W}[1]$-hard. Recently, it was shown
to be $\textsc{W}[1]$-complete by Abboud et al.~\cite{ALW14}.

The problem amounts to deciding in $n$-dimensional space, for each hyperplane
\(H\) of equation \(x_{i_1} + x_{i_2} + \cdots +x_{i_k} = 0\), whether \(q\)
lies on, above, or below \(H\). Hence this indeed amounts to locating the point
$q$ in the arrangement formed by those hyperplanes. We emphasize that the set
of hyperplanes depends only on $k$ and $n$ and not on the actual input vector
$q$.

\subsection{Uniform and Nonuniform Algorithms}

It has been long known that the \(k\)-SUM problem can be solved in time
$O(n^{\frac{k}{2}}\log n)$ for even $k$, and $O(n^{\frac{k+1}{2}})$ for odd
$k$. Erickson proved a near-matching lower bound in the $k$-linear
decision tree model~\cite{Er99a}. In this model, the complexity is measured by the depth of
a decision tree, every node of which corresponds to a query of the form
$q_{i_1} + q_{i_2} + \cdots + q_{i_k} \ask{\le} 0$, where $q_1, q_2, \ldots, q_n$ are the
input numbers. In a recent breakthrough paper, Gr\o nlund and
Pettie~\cite{GP18} showed that in the $(2k-2)$-linear decision tree model,
where queries test the sign of weighted sums of up to $2k-2$ input numbers, only
$O(n^\frac{k}{2}\sqrt{\log n})$ queries are required for odd values of $k$. In
particular, there exists a $4$-linear decision tree for 3SUM of depth
$\tilde{O}(n^\frac{3}{2})$, while every 3-linear decision tree has depth $\Omega
(n^2)$. This indicates that increasing the size of the queries,
defined as the maximum number of input numbers involved in a query, can yield
significant improvements on the depth of the minimal-height decision tree.

Ailon and Chazelle slightly extended the range of query sizes for which a
nontrivial lower bound could be established, elaborating on Erickson's
technique~\cite{AC05}.
%
They study \(s\)-linear decision trees to solve the \(k\)-SUM problem when
\(s > k\). In particular, they give an additional proof for the
$\Omega(n^{\ceil{\frac{k}{2}}})$ lower bound of Erickson and
generalize the lower bound for the \(s\)-linear decision tree model when \(s >
k\). Note that the exact lower bound given by Erickson for \(s = k\) is
$\Omega({(nk^{-k})}^{\ceil{\frac{k}{2}}})$ while the one given by
Ailon and Chazelle is $\Omega({(nk^{-3})}^{\ceil{\frac{k}{2}}})$. Their result
improves therefore the lower bound for \(s = k\) when \(k\) is large.
The lower bound they prove for \(s > k\) is the following
%
\input{text/theorem/AC05}
%
This lower bound breaks down when
\(k = \Omega(n^{\frac{1}{3}})\) or \(s \ge 2 k\) and the cases where \(k < 6\)
give trivial lower bounds. For example, in the case
of 3SUM with \(s = 4\) we only get an $\Omega(n)$ lower bound.

It has been well established that there exist nonuniform
polynomial-time algorithms for the subset-sum and knapsack problems.
%
Meyer auf der Heide~\cite{M84} was the first to use a point location algorithm to solve
the knapsack problem in the linear decision tree model in polynomial time. He
thereby answered a question raised by Dobkin and Lipton~\cite{DL74,DL78},
Yao~\cite{Y82} and others. However, if one uses this algorithm to locate a
point in an arbitrary arrangement of hyperplanes the running time is increased
by a factor linear in the greatest coefficient in the equations of all
hyperplanes.
%
A second algorithm was described by Meiser~\cite{M93}, and is derived from a
data structure for point location in arrangements of hyperplanes using the
bottom vertex decomposition.
%
The complexity of Meiser's point location algorithm is polynomial in the
dimension, logarithmic in the number of hyperplanes and does not depend on the
value of the coefficients in the equations of the hyperplanes. A useful
complete description of this algorithm is given by BÃ¼rgisser et al.~\cite{B97}
(Section 3.4).

When applied to \(k\)-SUM, those algorithms can be cast as the construction of
a linear decision tree in which the queries have non-constant size, even though
\(k\) is constant. They both yield \(n^{O(1)}\)-time nonuniform algorithms for
\(k\)-SUM where the constant of proportionality does not depend on \(k\).

\subsection{A variant: \(k\)-LDT}

Linear degeneracy testing (\(k\)-LDT) is a generalization of \(k\)-SUM where we
have arbitrary rational coefficients\footnote{The usual definition of \(k\)-LDT
allows arbitrary \emph{real} coefficients. However, the algorithm we provide
for Lemma~\ref{lem:multiple} needs the vertices of the arrangement of
hyperplanes to have rational coordinates.}
and an independent term in the equations
of the hyperplanes.
%
\input{text/definition/kldt}
%
Our algorithms apply to this more general problem with only minor changes.


\todo{Add reduction found in GP18.}

\todo{Add reduction found in KLM18.}
