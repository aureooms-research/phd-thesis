\section{Meiser Applied to \texorpdfstring{\(k\)-SUM}{k-SUM}}%
\label{sec:contribution:ksum-algorithm}

In Paper~\ref{paper:ksum-algorithm}
we focus on the computational complexity of \(k\)-SUM\@. We recall its
definition.
%
\ProblemKSUM*
%
In \S\ref{paper:ksum-algorithm:contrib:query-complexity}, we show the existence of an $n$-linear
decision tree of depth $\tilde{O}(n^3)$ for \(k\)-SUM using a careful
implementation of Meiser's algorithm~\cite{M93}.
%
Although the high-level algorithm itself is not new, we refine the
implementation and analysis for the \(k\)-SUM problem.%
\footnote{After submitting our results, we learned from a personal communication
with Herv\'e Fournier that a similar analysis for arbitrary hyperplanes appears in his PhD
thesis~\cite{F01} (in French).}
%
Meiser presented his algorithm as a general method of
$d$-dimensional
point location in the
arrangement of $m$ hyperplanes that yielded a
$\tilde{O}(d^4 \log m)$-depth algebraic computation tree;
%
when viewing the \(k\)-SUM problem as a point
location problem, with \(d=n\) and \(m = O(n^k)\),
Meiser's algorithm can be applied
to this problem, yielding
a \(\tilde{O}(n^4)\)-depth algebraic computation tree
(or a \(\tilde{O}(n^3)\)-depth linear decision tree).
%
In \S\ref{app:act},
we give a better analysis of this algorithm that
improves the depth of the algebraic computation tree to
\( \tilde{O}(n^3) \) for the \(k\)-SUM problem

There are two subtleties to this result. The first is inherent to the chosen
complexity model: even if the number of queries to the input is small (in
particular, the degree of the polynomial complexity is invariant on $k$), the
time required to \emph{determine which queries should be performed} may be
arbitrary. In a na\"ive analysis, we show it can be trivially bounded by
$\tilde{O}(n^{k+2})$.
%\footnote{%
	%Gr{\o}nlund and
	%Pettie~\cite{GP18} mention the algorithms of Meyer auf der Heyde~\cite{M84} and
	%Meiser~\cite{M93}, and state ``(\ldots) it was known that all \(k\)-LDT problems
	%can be solved by $n$-linear decision trees with depth $O(n^5\log
	%n)$~\cite{M93}, or with depth $O(n^4\log (nK))$ if the coefficients of the
	%linear function are integers with absolute value at most $K$~\cite{M84}.
	%Unfortunately these decision trees are not efficiently constructible. The
	%time required to determine \emph{which} comparisons to make is
	%exponential.'' We prove that the trees can have depth $\tilde{O}(n^3)$ and
	%that the whole algorithm can run in randomized polynomial-time.}
%
%
In \S\ref{paper:ksum-algorithm:contrib:time-complexity} we improve on this and present an
algorithm to choose which decisions to perform whereby the running time can be
reduced to $\tilde{O}(n^{\frac{k}{2}+8})$. Hence, we obtain an
$\tilde{O}(n^{\frac{k}{2}+8})$ time randomized algorithm in the RAM model
expected to perform $\tilde{O}(n^3)$ linear queries on the input.
%
\input{text/theorem/ksum-algorithm/decision-tree}

For those analyses, we consider algorithms in the standard word-RAM model with
$\Theta(\log n)$-size words, but in which the input $q\in\mathbb{R}^n$ is
accessible \emph{only} via a linear query oracle. Hence we are not allowed to
manipulate the input numbers directly. The complexity is measured in two ways:
by counting the total number of queries, just as in the linear decision tree
model, and by measuring the overall running time, taking into account the time
required to determine the sequence of linear queries. This two-track
computation model, in which the running time is distinguished from the query
complexity, is commonly used in results on comparison-based sorting problems
where analyses of both runtime and comparisons are of
interest~\cite{SS95,CFJJM10,CFJJM13}.

The second issue we address is that the linear queries in the above algorithm may
have size $n$, that is, they may use all the components of the input.
The lower bound of Erickson~\cite{Er99a} shows that if the queries are of minimal size, the number
of queries cannot be a polynomial independent of $k$ such as what we obtain, so
non-minimal query size is clearly essential to a drastic reduction in the number of queries needed.
This gives rise to the natural question as to what is the relation between query size and number of queries.
In particular, one natural question is whether queries of size less than $n$
would still allow the problem to be solved using a number of queries that is a
polynomial independent of $k$. We show that this is possible; in
\S\ref{paper:ksum-algorithm:contrib:query-size},
using a blocking scheme,
we introduce a family of
algorithms exhibiting an explicit tradeoff between the number of queries and
their size.
%
\input{text/theorem/ksum-algorithm/query-size}

We expose two corollaries of this contribution:
%
We show that we can restrict our algorithms to
use $o(n)$-linear queries while keeping the same complexity bounds, up to
polylogarithmic factors.
%
We also give a range of tradeoffs for $O(n^{1-\alpha})$-linear decision trees.
%
Although the proposed algorithms still involve nonconstant-size queries, this
is the first time such tradeoffs are explicitly tackled.
%
Table~\ref{tor:ksum-algorithm} summarizes our results.

\begin{table}
\centering
\caption{Complexities of past and new algorithms for the \(k\)-SUM problem.
%The query
%size is the maximum number of elements of the input that can be involved in a
%single linear query.
For our new algorithms,
the number of blocks is a parameter that allows us to
change the query size (see \S\ref{paper:ksum-algorithm:contrib:query-size}).
The origin of the constant in the exponent of the time complexity is due to
Lemma~\ref{lem:bound}. We conjecture it can be reduced, though substantial
changes in the analysis will likely be needed to do so.}
\label{tor:ksum-algorithm}
\begin{tabular}{|c|c|c|c|c|}
	\hline

	Reference & Blocks & Query Size & Queries & Time \\
	\hline
	\hline

	Folklore &
	-- &
	$k$ &
	$ \tilde{O}(n^{\lceil \frac k2 \rceil})$ &
	$ \tilde{O}(n^{\lceil \frac k2 \rceil})$
	\\

	\hline

	Meiser~\cite{M93} &
	-- &
	$n$ &
	$\tilde{O}(n^3)$~\S\ref{paper:ksum-algorithm:contrib:query-complexity} &
	$\tilde{O}(n^{k + 2})$~\S\ref{paper:ksum-algorithm:contrib:query-complexity}
	\\

	\hline

	\cite{GP18,GS15} &
	-- &
	$2k-2$ &
	$\tilde{O}(n^{\frac k2})$ &
	$\tilde{O}(n^{\frac k2})$
	\\

	\hline
	\hline

	\(\cdot\) (\ref{thm:cube}) &
	$1$ &
	$n$ &
	$\tilde{O}(n^3)$ \S\ref{paper:ksum-algorithm:contrib:query-complexity} &
	$\tilde{O}(n^{\lceil\frac{k}{2}+8\rceil})$ \S\ref{paper:ksum-algorithm:contrib:time-complexity}
	\\

	\hline

	\S\ref{paper:ksum-algorithm:contrib:query-size} (\ref{thm:query-size}) &
	$b$ &
	$k\lceil\frac{n}{b}\rceil$ &
	$\tilde{O}(b^{k-4}n^3)$ &
	$\tilde{O}(b^{\lfloor\frac{k}{2}-9\rfloor} n^{\lceil\frac{k}{2}+8\rceil})$
	\\

	\hline

	\S\ref{paper:ksum-algorithm:contrib:query-size} (\ref{cor:logn}) &
	$b=n^{\Theta(1)}$ &
	$o(n)$ &
	$\tilde{O}(n^3)$ &
	$\tilde{O}(n^{\lceil\frac{k}{2}+8\rceil})$
	\\

	\hline

	\S\ref{paper:ksum-algorithm:contrib:query-size} (\ref{cor:ne}) &
	$b=\Theta(n^\alpha)$ &
	$O(n^{1-\alpha})$ &
	$\tilde{O}(n^{3+(k-4)\alpha})$ &
	$\tilde{O}(n^{(1+\alpha)\frac{k}{2} +8.5})$
	\\

	\hline
\end{tabular}
\end{table}

